{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938bbd1b",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebooks creates model from images of documents\n",
    "It will choose the best model to use with them and then eliminate some features to get the better result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fbf45",
   "metadata": {},
   "source": [
    "### Import DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5fd0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "import multiprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d9135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9847b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "screenshots = pd.read_csv(\"./images/screenshots/screenshots.csv\")\n",
    "\n",
    "screenshots_ph = pd.read_csv(\"./images/screenshots_ph/screenshots_ph.csv\")\n",
    "\n",
    "receipts = pd.read_csv(\"./images/receipts/receipts.csv\")\n",
    "\n",
    "regulars = pd.read_csv(\"./images/regular/regular.csv\")\n",
    "\n",
    "not_good = pd.read_csv(\"./images/not_good/not_good.csv\")\n",
    "\n",
    "superb = pd.read_csv(\"./images/superb/superb.csv\")\n",
    "\n",
    "blinked = pd.read_csv(\"./images/blinked/blinked.csv\")\n",
    "\n",
    "docs = pd.read_csv(\"./images/docs/docs.csv\")\n",
    "\n",
    "test = pd.read_csv(\"./images/test/test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0a0cb",
   "metadata": {},
   "source": [
    "### Labeling and spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4929669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_labels = [\"blinked\", \"docs\", \"not_good\", \"receipts\", \"regular\", \"screenshots\", \"screenshots_ph\", \"superb\", \"test\"]\n",
    "\n",
    "label = \"docs\"\n",
    "\n",
    "blinked[label] = 0\n",
    "regulars[label] = 0\n",
    "not_good[label] = 0\n",
    "superb[label] = 0\n",
    "screenshots[label] = 0\n",
    "docs[label] = 1\n",
    "screenshots_ph[label] = 0\n",
    "receipts[label] = 0\n",
    "\n",
    "\n",
    "whole_docs = pd.concat([regulars, not_good, superb, screenshots, docs, receipts, screenshots_ph], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4001918",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_docs = whole_docs.drop(columns=[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4897f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = whole_docs.pop(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5c4833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(whole_docs, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1195777",
   "metadata": {},
   "source": [
    "## Running on 4 Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b148b",
   "metadata": {},
   "source": [
    "### ExtraTree simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d951f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers_3 as c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d21ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 324 candidates, totalling 3240 fits\n",
      "Time taken to train the model: 2 minutes and 30.44 seconds\n",
      "Best parameters: {'extratreesclassifier__min_samples_leaf': 1, 'extratreesclassifier__min_samples_split': 4, 'extratreesclassifier__n_estimators': 250}\n",
      "Best score: 0.9751120448179271\n"
     ]
    }
   ],
   "source": [
    "search_scr = c3.extratrees_model(X_train, y_train, c3.param_et)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6b10c",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c56070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n",
      "Time taken to train the model: 16 minutes and 57.21 seconds\n",
      "Best parameters: {'catboostclassifier__depth': 6, 'catboostclassifier__iterations': 300, 'catboostclassifier__l2_leaf_reg': 1e-20}\n",
      "Best score: 0.9716386554621849\n"
     ]
    }
   ],
   "source": [
    "search_cb = c3.catboost_model(X_train, y_train, c3.param_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8e7d2",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7930e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _log_callback at 0x7feb0b76e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anton/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/lightgbm/basic.py\", line 224, in _log_callback\n",
      "    def _log_callback(msg: bytes) -> None:\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m param_lgbm \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m50\u001b[39m), \n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m5\u001b[39m), \n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_samples\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 7\u001b[0m search_lgbm \u001b[38;5;241m=\u001b[39m \u001b[43mc3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlgbm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_lgbm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PYTHON/Pictureminator/classifiers_3.py:65\u001b[0m, in \u001b[0;36mlgbm_model\u001b[0;34m(X_train, y_train, param_lgbm)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Timing the fit operation\u001b[39;00m\n\u001b[1;32m     64\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 65\u001b[0m \u001b[43msearch_lgbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     68\u001b[0m total_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/PyENV/PICTUREMINATOR/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_lgbm = {\n",
    "        'n_estimators': range(100, 400, 50), \n",
    "        'num_leaves': range(20, 40, 5), \n",
    "        'min_child_samples': range(1, 20, 2)\n",
    "}\n",
    "\n",
    "search_lgbm = c3.lgbm_model(X_train, y_train, c3.param_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17cf133",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_adaboost = {\n",
    "        'n_estimators': range(50, 400, 50), \n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'estimator__max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "search_ab = c3.adaboost_model(X_train, y_train, c3.param_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328128e",
   "metadata": {},
   "source": [
    "### All 4 classifiers comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_et = search_scr.best_score_\n",
    "best_score_lgbm = search_lgbm.best_score_\n",
    "best_score_catboost = search_cb.best_score_\n",
    "best_score_adaboost = search_ab.best_score_\n",
    "\n",
    "# Create a list to display the results\n",
    "results = [\n",
    "    ('Extra Trees', best_score_et),\n",
    "    ('LightGBM', best_score_lgbm),\n",
    "    ('CatBoost', best_score_catboost),\n",
    "    ('AdaBoost', best_score_adaboost)\n",
    "]\n",
    "\n",
    "# Print the results in a tabular format\n",
    "print(f\"{'Classifier':<15}{f'Best Score - {label}'}\")\n",
    "for name, score in results:\n",
    "    print(f\"{name:<15}{score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f02774",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [search_scr, search_lgbm, search_cb, search_ab]\n",
    "\n",
    "results_with_identifiers = [\n",
    "    (search_scr, 'scr'),\n",
    "    (search_lgbm, 'lgbm'),\n",
    "    (search_cb, 'cb'),\n",
    "    (search_ab, 'ab')\n",
    "]\n",
    "\n",
    "classifier_mapping = {\n",
    "    'scr': 'ExtraTrees',\n",
    "    'lgbm': 'LightGBM',\n",
    "    'cb': 'CatBoost',\n",
    "    'ab': 'AdaBoost'\n",
    "}\n",
    "\n",
    "named_steps_estimator = {\n",
    "    'scr': 'extratreesclassifier',\n",
    "    'lgbm': 'lgbmclassifier',\n",
    "    'cb': 'adaboostclassifier',\n",
    "    'ab': 'adaboostclassifier'\n",
    "}\n",
    "\n",
    "\n",
    "best_model, best_identifier = results_with_identifiers[0]\n",
    "\n",
    "for model, identifier in results_with_identifiers[1:]:\n",
    "    if model.best_score_ > best_model.best_score_:\n",
    "        best_model = model\n",
    "        best_identifier = identifier\n",
    "\n",
    "# Use best_identifier to get the classifier name from the mapping\n",
    "classifier_name = classifier_mapping.get(best_identifier, 'Unknown')\n",
    "nsteps = named_steps_estimator.get(best_identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85cbcb9",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ace901",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test.pop(\"filename\")\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = search_lgbm.predict(test)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['filename'] = filenames\n",
    "result['prediction'] = prediction\n",
    "\n",
    "result.loc[(result.prediction == 1) & (result.filename.str.contains(label)), \"metric\"] = \"true\"\n",
    "result.loc[(result.prediction == 0) & (result.filename.str.contains(label)), \"metric\"] = \"FN\"\n",
    "result.loc[(result.prediction == 0) & (~result.filename.str.contains(label)), \"metric\"] = \"not true\"\n",
    "result.loc[(result.prediction == 1) & (~result.filename.str.contains(label)), \"metric\"] = \"FP\"\n",
    "\n",
    "result.groupby(\"metric\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f25893",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[result.metric == \"FP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920242d7",
   "metadata": {},
   "source": [
    "#### Confusion matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Define your color boundaries and corresponding colors\n",
    "boundaries = [0, 5, 10, 20, 50, 60, 70, 100]  # Assuming 80 is your max value\n",
    "colors = [\n",
    "    'darkgreen',  # 0-5\n",
    "    'green',      # 5-10\n",
    "    '#ffcccc',    # 10-20 (light red)\n",
    "    'red',        # 20-50\n",
    "    'lightblue',  # 50-60\n",
    "    'blue',       # 60-70\n",
    "    'darkblue'    # above 70\n",
    "]\n",
    "\n",
    "# Create a colormap\n",
    "custom_cmap = ListedColormap(colors)\n",
    "norm = BoundaryNorm(boundaries, custom_cmap.N, clip=True)\n",
    "\n",
    "\n",
    "tp = sum(result['metric'] == 'true')  \n",
    "fn = sum(result['metric'] == 'FN')    \n",
    "tn = sum(result['metric'] == 'not true')  \n",
    "fp = sum(result['metric'] == 'FP') \n",
    "\n",
    "conf_matrix = np.array([[tp, fn],\n",
    "                        [fp, tn]])\n",
    "\n",
    "# You can then plot this using seaborn or matplotlib\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_cmap, norm=norm, \n",
    "            xticklabels=['Positive', 'Negative'], \n",
    "            yticklabels=['Positive', 'Negative'])\n",
    "plt.ylabel('Actual Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb04f08",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eed6d2-e533-4105-bbc8-0d4ecb77089c",
   "metadata": {},
   "source": [
    "## Eliminating  features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bb8e5-a9f4-4bf6-8cc0-7588c4435497",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = best_model.best_estimator_\n",
    "search_RFE = RFECV(best_estimator.named_steps[nsteps], cv=10, scoring=\"accuracy\", n_jobs = multiprocessing.cpu_count() - 1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a7f8e-e685-4209-9f05-8bd8ef3da169",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "search_RFE.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24b437-9230-4a7e-ab3e-3163baff2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = search_RFE.predict(test)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['filename'] = filenames\n",
    "result['prediction'] = prediction\n",
    "\n",
    "result.loc[(result.prediction == 1) & (result.filename.str.contains(label)), \"metric\"] = \"true\"\n",
    "result.loc[(result.prediction == 0) & (result.filename.str.contains(label)), \"metric\"] = \"FN\"\n",
    "result.loc[(result.prediction == 0) & (~result.filename.str.contains(label)), \"metric\"] = \"not true\"\n",
    "result.loc[(result.prediction == 1) & (~result.filename.str.contains(label)), \"metric\"] = \"FP\"\n",
    "\n",
    "result.groupby(\"metric\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844516f-6b6b-421d-9939-6297b6b018b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a02c9079",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"./models/{label}_{classifier_name}.model\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(f\"Model saved successfully at {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
